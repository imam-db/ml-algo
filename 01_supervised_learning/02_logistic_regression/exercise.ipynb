{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises\n",
    "\n",
    "Welcome to the hands-on exercises for Logistic Regression! üéØ\n",
    "\n",
    "This notebook contains practical exercises to help you understand and master logistic regression concepts.\n",
    "\n",
    "## üìö Learning Objectives\n",
    "By completing these exercises, you will:\n",
    "- Understand the mathematical foundations of logistic regression\n",
    "- Implement logistic regression from scratch\n",
    "- Use scikit-learn for practical applications\n",
    "- Evaluate model performance using various metrics\n",
    "- Handle real-world classification problems\n",
    "- Tune hyperparameters for optimal performance\n",
    "\n",
    "## üèÅ Getting Started\n",
    "Run the cell below to import all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìö Ready to start learning Logistic Regression!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Understanding the Sigmoid Function üìà\n",
    "\n",
    "The sigmoid function is the heart of logistic regression. Let's explore it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "# TODO: Create a range of z values from -10 to 10\n",
    "z = np.linspace(-10, 10, 100)\n",
    "\n",
    "# TODO: Calculate sigmoid values\n",
    "sigmoid_values = sigmoid(z)\n",
    "\n",
    "# TODO: Plot the sigmoid function\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigmoid_values, 'b-', linewidth=3, label='Sigmoid Function')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Decision Threshold')\n",
    "plt.axvline(x=0, color='gray', linestyle=':', alpha=0.7)\n",
    "plt.xlabel('z (Linear Combination)', fontsize=12)\n",
    "plt.ylabel('œÉ(z) (Probability)', fontsize=12)\n",
    "plt.title('Sigmoid Function - The Heart of Logistic Regression', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()\n",
    "\n",
    "print(f\"When z=0: œÉ(z) = {sigmoid(0):.3f}\")\n",
    "print(f\"When z=2: œÉ(z) = {sigmoid(2):.3f}\")\n",
    "print(f\"When z=-2: œÉ(z) = {sigmoid(-2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 1.1\n",
    "**What happens to the sigmoid function as z approaches positive and negative infinity?**\n",
    "\n",
    "*Write your answer here:*\n",
    "\n",
    "### ü§î Question 1.2\n",
    "**Why is the sigmoid function perfect for binary classification?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Generate and Visualize Classification Data üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a synthetic binary classification dataset\n",
    "# Use make_classification with:\n",
    "# - n_samples=500\n",
    "# - n_features=2 (for easy visualization)\n",
    "# - n_redundant=0\n",
    "# - n_informative=2\n",
    "# - random_state=42\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Create a scatter plot to visualize the data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='red', alpha=0.6, label='Class 0', s=50)\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='blue', alpha=0.6, label='Class 1', s=50)\n",
    "plt.xlabel('Feature 1', fontsize=12)\n",
    "plt.ylabel('Feature 2', fontsize=12)\n",
    "plt.title('Binary Classification Dataset', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "print(f\"Feature 1 range: [{X[:, 0].min():.2f}, {X[:, 0].max():.2f}]\")\n",
    "print(f\"Feature 2 range: [{X[:, 1].min():.2f}, {X[:, 1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Train Your First Logistic Regression Model üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and testing sets\n",
    "# Use test_size=0.2 and random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TODO: Create and train a LogisticRegression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# TODO: Calculate and display performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"üìä Model Performance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "# Display model coefficients\n",
    "print(f\"\\nüî¢ Model Coefficients:\")\n",
    "print(f\"Intercept (Œ≤‚ÇÄ): {model.intercept_[0]:.4f}\")\n",
    "print(f\"Feature 1 (Œ≤‚ÇÅ): {model.coef_[0][0]:.4f}\")\n",
    "print(f\"Feature 2 (Œ≤‚ÇÇ): {model.coef_[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 3.1\n",
    "**What do the coefficients tell you about the importance of each feature?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Visualize the Decision Boundary üé®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model, title=\"Decision Boundary\"):\n",
    "    \"\"\"Plot decision boundary for 2D data\"\"\"\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "    plt.colorbar(label='Probability of Class 1')\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='--', linewidths=3)\n",
    "    \n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', edgecolors='black', s=50)\n",
    "    plt.xlabel('Feature 1', fontsize=12)\n",
    "    plt.ylabel('Feature 2', fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Plot the decision boundary for your model\n",
    "plot_decision_boundary(X_test, y_test, model, \"Logistic Regression Decision Boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 4.1\n",
    "**What does the decision boundary represent? Why is it linear?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: ROC Curve Analysis üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=3, \n",
    "         label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# TODO: Find the optimal threshold\n",
    "# Calculate Youden's J statistic (TPR - FPR)\n",
    "j_scores = tpr - fpr\n",
    "optimal_idx = np.argmax(j_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"üìä ROC Analysis:\")\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"TPR at optimal threshold: {tpr[optimal_idx]:.4f}\")\n",
    "print(f\"FPR at optimal threshold: {fpr[optimal_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 5.1\n",
    "**What does an AUC of 0.5 mean? What about 1.0?**\n",
    "\n",
    "*Write your answer here:*\n",
    "\n",
    "### ü§î Question 5.2\n",
    "**When would you use a different threshold than 0.5?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 6: Real-World Dataset - Breast Cancer Diagnosis üè•\n",
    "\n",
    "Now let's work with a real medical dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X_cancer, y_cancer = data.data, data.target\n",
    "\n",
    "print(\"üè• Breast Cancer Dataset Information:\")\n",
    "print(f\"Dataset shape: {X_cancer.shape}\")\n",
    "print(f\"Number of features: {X_cancer.shape[1]}\")\n",
    "print(f\"Classes: {data.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y_cancer)}\")\n",
    "print(f\"\\nFirst 5 feature names:\")\n",
    "for i, name in enumerate(data.feature_names[:5]):\n",
    "    print(f\"  {i+1}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# TODO: Apply feature scaling (very important for this dataset!)\n",
    "scaler = StandardScaler()\n",
    "X_train_cancer_scaled = scaler.fit_transform(X_train_cancer)\n",
    "X_test_cancer_scaled = scaler.transform(X_test_cancer)\n",
    "\n",
    "# TODO: Train logistic regression with and without scaling\n",
    "# Model without scaling\n",
    "model_unscaled = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_unscaled.fit(X_train_cancer, y_train_cancer)\n",
    "\n",
    "# Model with scaling\n",
    "model_scaled = LogisticRegression(random_state=42)\n",
    "model_scaled.fit(X_train_cancer_scaled, y_train_cancer)\n",
    "\n",
    "# TODO: Compare performance\n",
    "y_pred_unscaled = model_unscaled.predict(X_test_cancer)\n",
    "y_pred_scaled = model_scaled.predict(X_test_cancer_scaled)\n",
    "\n",
    "acc_unscaled = accuracy_score(y_test_cancer, y_pred_unscaled)\n",
    "acc_scaled = accuracy_score(y_test_cancer, y_pred_scaled)\n",
    "\n",
    "print(\"üìä Feature Scaling Impact:\")\n",
    "print(f\"Accuracy without scaling: {acc_unscaled:.4f}\")\n",
    "print(f\"Accuracy with scaling:    {acc_scaled:.4f}\")\n",
    "print(f\"Improvement: {acc_scaled - acc_unscaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 6.1\n",
    "**Why does feature scaling improve performance so much for this dataset?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze feature importance\n",
    "feature_importance = np.abs(model_scaled.coef_[0])\n",
    "top_features_idx = np.argsort(feature_importance)[-10:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_10_features = feature_importance[top_features_idx]\n",
    "top_10_names = [data.feature_names[i] for i in top_features_idx]\n",
    "\n",
    "plt.barh(range(len(top_10_features)), top_10_features, color='skyblue')\n",
    "plt.yticks(range(len(top_10_features)), top_10_names)\n",
    "plt.xlabel('Coefficient Magnitude', fontsize=12)\n",
    "plt.title('Top 10 Most Important Features (Breast Cancer Diagnosis)', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Top 5 Most Important Features:\")\n",
    "for i, idx in enumerate(reversed(top_features_idx[-5:])):\n",
    "    print(f\"{i+1}. {data.feature_names[idx]}: {feature_importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7: Hyperparameter Tuning Challenge üéõÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different C values (regularization strength)\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for C in C_values:\n",
    "    # TODO: Train model with different C values\n",
    "    model = LogisticRegression(C=C, random_state=42)\n",
    "    model.fit(X_train_cancer_scaled, y_train_cancer)\n",
    "    \n",
    "    # TODO: Calculate scores\n",
    "    train_score = model.score(X_train_cancer_scaled, y_train_cancer)\n",
    "    test_score = model.score(X_test_cancer_scaled, y_test_cancer)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    print(f\"C={C:7.3f}: Train={train_score:.4f}, Test={test_score:.4f}\")\n",
    "\n",
    "# TODO: Plot the regularization path\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.semilogx(C_values, train_scores, 'b-o', label='Training Accuracy', linewidth=2)\n",
    "plt.semilogx(C_values, test_scores, 'r-o', label='Test Accuracy', linewidth=2)\n",
    "plt.xlabel('C (Inverse of Regularization Strength)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Regularization Path - Effect of C Parameter', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Find best C\n",
    "best_idx = np.argmax(test_scores)\n",
    "best_C = C_values[best_idx]\n",
    "print(f\"\\nüèÜ Best C value: {best_C}\")\n",
    "print(f\"Best test accuracy: {test_scores[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 7.1\n",
    "**What happens when C is very small vs very large? Which indicates overfitting?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 8: Cross-Validation Deep Dive üîÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform cross-validation with different scoring metrics\n",
    "model = LogisticRegression(C=best_C, random_state=42)\n",
    "\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "cv_results = {}\n",
    "\n",
    "print(\"üîÑ Cross-Validation Results (5-fold):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for metric in scoring_metrics:\n",
    "    scores = cross_val_score(model, X_train_cancer_scaled, y_train_cancer, \n",
    "                           cv=5, scoring=metric)\n",
    "    cv_results[metric] = scores\n",
    "    print(f\"{metric:10s}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# TODO: Create a box plot of CV scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "data_for_boxplot = [cv_results[metric] for metric in scoring_metrics]\n",
    "plt.boxplot(data_for_boxplot, labels=scoring_metrics)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Cross-Validation Scores Distribution', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 9: Create Your Own Implementation üõ†Ô∏è\n",
    "\n",
    "Challenge: Implement a simplified version of logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        # TODO: Implement the sigmoid function\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # TODO: Initialize weights and bias\n",
    "        n_features = X.shape[1]\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # TODO: Implement gradient descent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Forward pass\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            dw = (1/len(X)) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/len(X)) * np.sum(predictions - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: Implement probability prediction\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # TODO: Implement binary prediction\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities >= 0.5).astype(int)\n",
    "\n",
    "# TODO: Test your implementation\n",
    "my_model = SimpleLogisticRegression(learning_rate=0.1, max_iterations=1000)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "my_predictions = my_model.predict(X_test)\n",
    "my_accuracy = accuracy_score(y_test, my_predictions)\n",
    "\n",
    "print(f\"üöÄ Your Implementation Results:\")\n",
    "print(f\"Accuracy: {my_accuracy:.4f}\")\n",
    "print(f\"Weights: {my_model.weights}\")\n",
    "print(f\"Bias: {my_model.bias:.4f}\")\n",
    "\n",
    "# Compare with sklearn\n",
    "sklearn_model = LogisticRegression(random_state=42)\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "sklearn_accuracy = sklearn_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"Your implementation: {my_accuracy:.4f}\")\n",
    "print(f\"Scikit-learn:       {sklearn_accuracy:.4f}\")\n",
    "print(f\"Difference:         {abs(my_accuracy - sklearn_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Question 9.1\n",
    "**How close is your implementation to scikit-learn's? What could cause differences?**\n",
    "\n",
    "*Write your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Final Challenge: Build a Complete Classification Pipeline\n",
    "\n",
    "Put everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_classification_pipeline(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Complete end-to-end classification pipeline\n",
    "    \n",
    "    TODO: Complete this function to include:\n",
    "    1. Data splitting\n",
    "    2. Feature scaling\n",
    "    3. Model training\n",
    "    4. Hyperparameter tuning\n",
    "    5. Model evaluation\n",
    "    6. Visualization\n",
    "    \n",
    "    Returns: trained model, performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement the complete pipeline\n",
    "    print(\"üöÄ Starting Complete Classification Pipeline...\")\n",
    "    \n",
    "    # 1. Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"‚úÖ Data split: {X_train.shape[0]} train, {X_test.shape[0]} test\")\n",
    "    \n",
    "    # 2. Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"‚úÖ Features scaled\")\n",
    "    \n",
    "    # 3. Model training with best hyperparameters\n",
    "    model = LogisticRegression(C=1.0, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"‚úÖ Model trained\")\n",
    "    \n",
    "    # 4. Evaluation\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüìä Final Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.upper():10s}: {value:.4f}\")\n",
    "    \n",
    "    return model, scaler, metrics\n",
    "\n",
    "# TODO: Run your pipeline on the breast cancer dataset\n",
    "final_model, final_scaler, final_metrics = complete_classification_pipeline(\n",
    "    X_cancer, y_cancer\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Congratulations!\n",
    "\n",
    "You've completed all the Logistic Regression exercises! üéâ\n",
    "\n",
    "### What you've learned:\n",
    "- ‚úÖ Understanding the sigmoid function\n",
    "- ‚úÖ Mathematical foundations of logistic regression\n",
    "- ‚úÖ Implementation from scratch\n",
    "- ‚úÖ Using scikit-learn effectively\n",
    "- ‚úÖ Feature scaling importance\n",
    "- ‚úÖ Hyperparameter tuning\n",
    "- ‚úÖ Model evaluation techniques\n",
    "- ‚úÖ Cross-validation\n",
    "- ‚úÖ Real-world application\n",
    "\n",
    "### Next steps:\n",
    "1. Try logistic regression on your own datasets\n",
    "2. Experiment with regularization (L1 vs L2)\n",
    "3. Learn about multinomial logistic regression\n",
    "4. Compare with other classification algorithms\n",
    "5. Study advanced topics like class imbalance handling\n",
    "\n",
    "### ü§î Final Reflection Questions:\n",
    "\n",
    "1. **When would you choose logistic regression over other algorithms?**\n",
    "\n",
    "*Write your answer here:*\n",
    "\n",
    "2. **What are the main limitations of logistic regression?**\n",
    "\n",
    "*Write your answer here:*\n",
    "\n",
    "3. **How would you handle a dataset with 10 classes using logistic regression?**\n",
    "\n",
    "*Write your answer here:*\n",
    "\n",
    "Great job! üåü Keep practicing and exploring!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}